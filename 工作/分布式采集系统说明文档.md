# 分布式采集系统说明文档

## 概述

分布式采集系统是用于进行数据采集的系统，目前可以进行新闻类型、搜索类型、社交媒体类型的数据采集，代码项目上分为control（控制单元项目）、datacollection（公共引用项目）、collections（采集单元项目），逻辑上分为控制单元和采集单元两个模块。

## 控制单元

控制单元主要用于管理信源、控制信源的流转流程、管理采集池等。

### 流程

#### 信源采集

1. 从数据库和redis中读取待采集的信源

2. 将信源封装成一个`PageReq`（采集请求）

3. 将采集请求加入到待采集池

4. “待采集池”取出队头的采集请求请求调度采集单元

5. 调度成功后将采集请求加入到“正在采集池”

6. 采集完成后，采集单元返回一个`ResultMessage`类型的消息

7. 控制单元接收到返回的采集结果，根据内容类型判断走什么逻辑

8. 如果采集结果是列表类型，则取出列表中的url，将url封装为一个新的采集请求，然后加入到“待采集缓存池”

9. 如果采集结果是内容类型，则将采集的内容，根据不同数据类型，进行各自逻辑的处理后进行存储，并且将返回的文件url，构建为一个采集请求加入到“文件采集池”

#### 文件采集

文件采集采用的是断点续传的方式进行采集传输的。

1. 从“文件采集池”取出一个采集请求，加入到“待采集池”

2. 然后执行[“信源采集”](#_信源采集)的流程

3.    采集完成后，会返回`ResultFile`类型的信息

4. 采集会返回文件的流以及位置信息，然后控制单元通过`RandomAccessFile`临时存储到本地，当文件完全采集后将文件上传到minio，然后删除临时文件。

#### 信源采集超时机制

信源采集超时机制是为了处理采集时间过长的信源。

1. 启动一个无限循环的线程
2. 每秒钟从**正在采集池**遍历数据
3. 如果采集的时间超过了预设的最大采集时间，则会将数据从**正在采集池**移至待采集池
4. 并且将数据存储至**已超时池**。

#### 动态jar包

动态jar包用于自定义采集，如果智能采集不能采集到想要的数据，可以通过配置动态jar包，来实现自定义的采集。

推送jar包到采集单元：

1. 从数据库读取所有的动态jar包信息
2. 构建`DynamicJarMsg`消息推送给采集单元

接收采集单元推送的动态jar消息：

1. 从消息体中取出需要同步的jar包信息
2. 从minio下载jar包
3. 将jar包推送给采集单元

#### 调度采集单元

1. 根据信源是境内还是境外，获取调度池中的节点，默认使用最快节点（如果信源是境外，但是没有可用的境外节点，则会随机取一个最快节点）
2. 获取节点的channel
3. 发送请求

### 采集池

采集池用于控制信源采集的流转，分为待采集池、文件采集池、正在采集池、待采集缓存池、已完成采集池。

#### 待采集池

待采集池是用于存储即将需要采集的信源采集请求的采集池，netty心跳时，会从文件采集池、待采集缓存池、数据库，取出需要采集的数据，封装为`PageReq`，然后加入到待采集池。

实现方式：

redis的zset数据接口，根据`sourcecycle`表的`nexttime`字段进行排序。

#### 文件采集池

文件采集池是用于存储采集单元返回`BaseResultMessage`的`filesList`里的文件url构建的`PageReq`，在netty心跳时将PageReq流转至**待采集池**。

实现方式：

redis的list数据结构。

#### 正在采集池

正在采集池是用于存储调度**采集单元**成功的`PageReq`，netty心跳时会从**待采集池**取出一个PageReq，调度**采集单元**后加入到正在采集池。

实现方式：

redis的hash结构，key：`PageReq.id`，value：`PageReq`

#### 待采集缓存池

待采集缓存池是用于存储采集单元返回`BaseResultMessage`的`linksList`里的信源url构建的`PageReq`，在netty心跳时将PageReq流转至**待采集池**。

实现方式：

redis的list数据结构。

#### 已完成采集池

用于存储采集完成的数据，分为采集数据存储，采集记录存储。

采集数据存储，根据采集单元返回的数据类型，进行不同逻辑后存储到`MongoDB`。

采集记录存储，将采集完成的`PageReq`从正在采集池取出，然后存储到`Elasticsearch`，不管采集成功还是失败。

#### 已超时信源采集池

用于存储采集超时的信源的采集记录信息。

实现方式：

Elasticsearch

### 调度池

调度池用于存储采集节点的信息。

调度池实现：

redis的hash结构

key：ip

value：`CollectionInfoMessageAndHardware`

## 采集单元

采集单元用于对数据进行采集，执行真正的采集操作。

1. 采集单元接收到`PageReqMessage`，解析`PageReqMessage`后存入队列

2. Collections项目的`NettyBootsrapRunner`的`entryDataCollectionThread()`方法是采集的入口

3. 将队列的数据放入线程中执行
4. 加入采集监控信息列表
5. 根据`PageReq`的类型进行不同的采集
6. 删除采集监控信息列表
7. 返回消息给控制单元

### 新闻采集

新闻采集：控制单元推送一个类型为1的PageReq消息，采集单元接收，采集单元第一次采集新闻的列表的url，将url列表返回给控制单元，控制单元将url列表解析后，封装为一个一个的`PageReq`，然后在推给采集单元进行采集，采集单元采集url里的新闻内容，然后返回给控制单元。

1. 从`QueueManage`里获取一个`pagereq`进行数据采集
2. 通过反射生成`Interactive`
3. 判断当前所需要使用的采集器是动态的还是静态的
4. 获取动作信息并加入到链式动作pipeline管理器中
5. 开始请求url，拿到html和获取网站返回的异步数据
6. 通过`Jsoup`解析html
7. 如果`newsFormatSelect`为空则开始自动配置
8. 开始构建一个newsFormatSelect(内容只有图片和内容) title
9. 存储newsFormatSelect
10. 进行通用匹配解析
11. 如果`newsFormatSelect`不为空
12. 则根据配置的select进行解析
13. 解析完成后返回结果`NewsResult`给控制单元

### 搜索采集

搜索采集：控制单元推送一个类型为5的PageReq消息，采集单元接收采集，控制单元有两类搜索采集，一类是数据库配置的信源，一类是外部暴露接口提供的信源，数据库配置的信源采集完成后会存储到mongoDB，外部提供的信源则是先存储到redis，通过接口暴露出去。

1.  从`QueueManage`里获取一个`pagereq`进行数据采集
2. 通过反射生成`Interactive`
3. 如果`PageReq`类型是5则组合url
4. 判断当前所需要使用的采集器是动态的还是静态的
5. 获取动作信息并加入到链式动作pipeline管理器中
6. 开始请求url，拿到html和获取网站返回的异步数据
7. 通过`Jsoup`解析html
8. 解析完成后返回结果`searchContentList`给控制单元

### 社交媒体采集

社交媒体采集：控制单元推送一个类型为3的消息，采集单元接收采集，返回数据给控制单元。

1. 从`QueueManage`里获取一个`pagereq`进行数据采集
2. 通过反射生成`Interactive`
3. 判断当前所需要使用的采集器是动态的还是静态的
4. 获取推文的异步请求
5. 将用户信息和推文信息存入到`twitterUser`和`twitterTextList`
6. 获取动作信息并加入到链式动作pipeline管理器中
7. 开始请求url，拿到html
8. 通过`Jsoup`解析html
9. 下载图片和文件
10. 返回`TwitterResult`

### 文件采集

文件采集是普通信源采集的文件url又重新封装的PageReq推送给采集单元进行采集的流程。

1. 控制单元推送一个类型为6的PageReq
2. 采集单元执行`FileUtil.startDownload(pageReq);`
3. 开始下载数据信息，下载完成存储到本地
4. 通过okhttp3进行文件的下载
5. 采集单元在启动的时候会启动一个”文件下载线程“
6. 文件下载线程会遍历下载到本地的文件
7. 将文件通过netty进行断点续传给控制单元

### 动态jar包

接收控制单元推送的`DynamicJarMsg`：

1. 判断`DynamicJarMsg`里的classList是否为空
2. 如果不为空则取出jar包的文件流，然后将jar加载的内存中
3. 如果为空则代表是心跳推送的动态jar信息
4. 然后比较本地的已经同步的jar信息
5. 将与控制单元同步的jar信息不同的jar信息封装后推送给控制单元
6. 让控制单元推送需要更新的jar文件流

## 模型说明

### 采集请求模型

#### PageReq

```java
package com.datacollection.unit.model;

import java.io.Serializable;
import java.util.*;

import com.alibaba.fastjson.JSONObject;
import com.datacollection.unit.model.entity.Actionlist;
import com.datacollection.unit.model.entity.BaseSelect;
import com.datacollection.unit.util.UserAgentUtil;

import lombok.Data;
/**
 * 链式管理单元组最小单元
 */
@Data
public class PageReq implements Comparable<PageReq>, Serializable, Cloneable{
    private static final long serialVersionUID = 593490123268L;
    private long id=0;//对应的id信息,此id可以关联到（自动）配置信息
    private long preId=0;//对应的上一级单元组的id信息
    private long flag;//对应的标签id 如：生活、科技、政务、教育等
    private int type=0; //(1、新闻内容类 2、论坛类 3、社交媒体类 4、知识类 5、搜索类 6、文件类)需要采集的url分为采集当前的
    //如果当前是社交媒体类时 0未知 1用户主页 2社交搜索
    private int subType = 0;//4、表示百度搜索
    private int contentType=0;//内容类型==0未知、1链接和链接列表、2内容（这里就不需要链式1和3则需要开启链式）、3内容+链接（这里包含需要加入排除和白名单链接）4、表示百度搜索
    private String parserFullName ="";//对应的采集器全类名称
    private boolean used;//是否需要采集
    private boolean isTest;//是否是测试
    @Deprecated
    private boolean enableLinkedCollection;//启用链式采集
    private String wsEndPoint=""; //动态页面的远程连接ws
    private String url=""; //当前请求的url
    private Map<String, String> reqParams = new HashMap<>();; //当前请求参数 （暂时未使用 get请求直接跟在url中）
    private Map<String, String> reqCookies= new HashMap<>();; //当前cookies
    private Map<String, String> reqHeads= new HashMap<>();; //当前请求头
    private String userAgent = UserAgentUtil.getUserAgent(UserAgentUtil.getPcUserAgent()); //当前请求agent
    private String referer=""; //当前请求的页面地址
    private int timeout=8000; //当前请求的超时时间
    private boolean isPost=false; //当前请求是否是post请求
    private boolean isExistPostFormBody;//当前是表格形式请求体
    private Map<String,String> postFormBody = new HashMap<>();//post方式下以表格形式请求体的内容
    private String text="";//post方式下以文本为请求体的内容 普通文本或者json    当为文件时则传送的是后缀名
    private String requestMediaType = "text/html; charset=UTF-8";//请求内容类型 "application/json; charset=UTF-8" "text/html; charset=UTF-8"  "application/x-www-form-urlencoded"
    private boolean validateHttps; //是否需要验证https
    private boolean useProxy;
    private boolean useProxyAuth;
    private String  proxyIp=""; //当前代理ip
    private int proxyPort;//当前代理端口
    private String proxyUsername="";
    private String proxyPassword="";
    private Set<String> filterUrl = Collections.synchronizedSet(new HashSet<String>());//过滤指定url 完整url
    private Set<String> addUrl = Collections.synchronizedSet(new HashSet<String>());//增加指定特例url 完整url
    private Set<String> whiteUrlList = Collections.synchronizedSet(new HashSet<String>());//白名单规则(支持正则) 先根据白名单规则获取到url然后再过滤filterUrl中的url再增加addurl
    private List<String> waitUntil = new ArrayList<>();//页面加载成功的终结点
    private boolean enableStatic=true;//当前使用的采集器是动态的还是静态的
    private List<Actionlist> pipelineActionManage = new ArrayList<>(); //响应时返回时为采集的内容
    private boolean enableInterception;//开启请求结果拦截
    // private String searchContent;//针对于交互式搜索的内容信息
    private BaseSelect select = new BaseSelect();//对应的样式model不同的各类对应的model不同 SearchContentFormatSelect NewsFormatSelect等
    private int curPageIndex;//当前对应的页数-----------此针对于搜索
    private boolean savePosition;//保存位置：如果是交互式采集需要显示时可将数据推入缓存中redis等必需设置过期时间 // true手动搜索，false自动搜索
    private int priority;//优先级，根据优先级设置执行顺序
    private boolean trust;//是否是可信节点 放入不同的采集池中
    private Long startTime=0L;//开始采集时间
    private Long endTime=0L;//结束采集时间
    private Long sourceId=0L;//信源雪花id
    private String name; // 信源名称
    private int reCollectNum=0; // 采集重试次数
    private Double collectionNodeLatitude; // 采集节点纬度
    private Double collectionNodeLongitude; // 采集节点经度
    private String collectionNodeIp; // 采集节点ip
    private String remoteAddress; // 网页来源的服务器ip
    private Double remoteAddressLatitude; // 网页来源的服务器纬度
    private Double remoteAddressLongitude; // 网页来源的服务器经度
    private String controlNodeIp; // 控制节点ip
    private Double controlNodeLatitude; // 控制节点纬度
    private Double controlNodeLongitude; // 控制节点精度
    private Boolean isDomestic; // 境内境外
    @Override
    public int compareTo(PageReq o) {
        return this.priority > o.getPriority()?-1:1;
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        PageReq pageReq = (PageReq) o;
        return id == pageReq.id && preId == pageReq.preId && flag == pageReq.flag && type == pageReq.type && contentType == pageReq.contentType && used == pageReq.used && isTest == pageReq.isTest && enableLinkedCollection == pageReq.enableLinkedCollection && timeout == pageReq.timeout && isPost == pageReq.isPost && isExistPostFormBody == pageReq.isExistPostFormBody && validateHttps == pageReq.validateHttps && useProxy == pageReq.useProxy && useProxyAuth == pageReq.useProxyAuth && proxyPort == pageReq.proxyPort && enableStatic == pageReq.enableStatic && enableInterception == pageReq.enableInterception && curPageIndex == pageReq.curPageIndex && savePosition == pageReq.savePosition && priority == pageReq.priority && trust == pageReq.trust && Objects.equals(parserFullName, pageReq.parserFullName) && Objects.equals(wsEndPoint, pageReq.wsEndPoint) && Objects.equals(url, pageReq.url) && Objects.equals(reqParams, pageReq.reqParams) && Objects.equals(reqCookies, pageReq.reqCookies) && Objects.equals(reqHeads, pageReq.reqHeads) && Objects.equals(userAgent, pageReq.userAgent) && Objects.equals(referer, pageReq.referer) && Objects.equals(postFormBody, pageReq.postFormBody) && Objects.equals(text, pageReq.text) && Objects.equals(requestMediaType, pageReq.requestMediaType) && Objects.equals(proxyIp, pageReq.proxyIp) && Objects.equals(proxyUsername, pageReq.proxyUsername) && Objects.equals(proxyPassword, pageReq.proxyPassword) && Objects.equals(filterUrl, pageReq.filterUrl) && Objects.equals(addUrl, pageReq.addUrl) && Objects.equals(whiteUrlList, pageReq.whiteUrlList) && Objects.equals(waitUntil, pageReq.waitUntil) && Objects.equals(pipelineActionManage, pageReq.pipelineActionManage) && Objects.equals(select, pageReq.select) && Objects.equals(startTime, pageReq.startTime) && Objects.equals(endTime, pageReq.endTime) && Objects.equals(sourceId, pageReq.sourceId);
    }

    @Override
    public int hashCode() {
        return Objects.hash(id, preId, flag, type, contentType, parserFullName, used, isTest, enableLinkedCollection, wsEndPoint, url, reqParams, reqCookies, reqHeads, userAgent, referer, timeout, isPost, isExistPostFormBody, postFormBody, text, requestMediaType, validateHttps, useProxy, useProxyAuth, proxyIp, proxyPort, proxyUsername, proxyPassword, filterUrl, addUrl, whiteUrlList, waitUntil, enableStatic, pipelineActionManage, enableInterception, select, curPageIndex, savePosition, priority, trust, startTime, endTime, sourceId);
    }

    @Override
    public String toString() {
        return JSONObject.toJSONString(this);
//        return "PageReq{" +
//                "id=" + id +
//                ", preId=" + preId +
//                ", flag=" + flag +
//                ", type=" + type +
//                ", contentType=" + contentType +
//                ", parserFullName='" + parserFullName + '\'' +
//                ", used=" + used +
//                ", isTest=" + isTest +
//                ", enableLinkedCollection=" + enableLinkedCollection +
//                ", wsEndPoint='" + wsEndPoint + '\'' +
//                ", url='" + url + '\'' +
//                ", reqParams=" + reqParams +
//                ", reqCookies=" + reqCookies +
//                ", reqHeads=" + reqHeads +
//                ", userAgent='" + userAgent + '\'' +
//                ", referer='" + referer + '\'' +
//                ", timeout=" + timeout +
//                ", isPost=" + isPost +
//                ", isExistPostFormBody=" + isExistPostFormBody +
//                ", postFormBody=" + postFormBody +
//                ", text='" + text + '\'' +
//                ", requestMediaType='" + requestMediaType + '\'' +
//                ", validateHttps=" + validateHttps +
//                ", useProxy=" + useProxy +
//                ", useProxyAuth=" + useProxyAuth +
//                ", proxyIp='" + proxyIp + '\'' +
//                ", proxyPort=" + proxyPort +
//                ", proxyUsername='" + proxyUsername + '\'' +
//                ", proxyPassword='" + proxyPassword + '\'' +
//                ", filterUrl=" + filterUrl +
//                ", addUrl=" + addUrl +
//                ", whiteUrlList=" + whiteUrlList +
//                ", waitUntil=" + waitUntil +
//                ", enableStatic=" + enableStatic +
//                ", pipelineActionManage=" + pipelineActionManage +
//                ", enableInterception=" + enableInterception +
//                ", select=" + select +
//                ", curPageIndex=" + curPageIndex +
//                ", savePosition=" + savePosition +
//                ", priority=" + priority +
//                ", trust=" + trust +
//                ", startTime=" + startTime +
//                ", endTime=" + endTime +
//                ", sourceId=" + sourceId +
//                '}';
    }

    @Override
    public PageReq clone() throws CloneNotSupportedException {
        return (PageReq) super.clone();
    }
}

```

### 采集单元采集数据返回模型

#### 父类

##### BaseResultMessage

```java
package com.datacollection.unit.message.result;

import java.io.Serializable;
import java.util.*;

import lombok.Data;

/**
 * 返回的结果类需要继承此类
 */
@Data
public class BaseResultMessage implements Serializable {
    private static final long serialVersionUID = 123456789L;
    private long sourceId;//信源id
    private String MD5 = "";//内容对应的md5值
    private boolean status;//是否获取成功
    private Object result;//返回的结果
    // private Long fakeSnow;//雪花
    private int contentType;//判断内容是否为列表
    private long id;//雪花id 当前页面id
    private long preID;//父级id
    private String url = "";//当前链接
    private Set<String> linksList = new HashSet<>(); // 需要加入待采集的信源，如果是列表，则从这里取值
    private Map<String,String> filesList = new HashMap<>();// 需要采集的文件url列表
    private Date collectionEndTime; // 采集完成时间
    private Double collectionNodeLatitude; // 采集节点纬度
    private Double collectionNodeLongitude; // 采集节点经度
    private String collectionNodeIp; // 采集节点ip
    private String remoteAddress; // 网页来源的服务器ip
    private Double remoteAddressLatitude; // 网页来源的服务器纬度
    private Double remoteAddressLongitude; // 网页来源的服务器经度
    private String controlNodeIp; // 控制节点ip
    private Double controlNodeLatitude; // 控制节点纬度
    private Double controlNodeLongitude; // 控制节点精度
}

```

#### 新闻类型

##### NewsResult

```java
package com.datacollection.unit.model.news;

import com.datacollection.unit.message.result.BaseResultMessage;

import lombok.Data;
import lombok.EqualsAndHashCode;
@Data
@EqualsAndHashCode(callSuper=false)
public class NewsResult extends BaseResultMessage{
    private NewsFormatANDSelect newsFormatANDSelect;
}

```

##### NewsFormatANDSelect

```java
package com.datacollection.unit.model.news;
import java.io.Serializable;

import lombok.Data;
import lombok.EqualsAndHashCode;
@Data
@EqualsAndHashCode(callSuper=false)
public class NewsFormatANDSelect implements Serializable {
    private static final long serialVersionUID = 1556645500000L;
    private NewsFormat newsFormat;
    private NewsFormatSelect newsFormatSelect;
}

```

##### NewsFormat

```java
package com.datacollection.unit.model.news;

import java.io.Serializable;
import java.util.List;
import com.datacollection.unit.model.parser.PElement;

import lombok.Data;

/**
 * 新闻内容类的格式
 */
@Data
public class NewsFormat implements Serializable {
    private static final long serialVersionUID = 435892201L;
    private long id;//全局唯一id
    private long sourceId;//信源id
    private long preID;//对应的上一级唯一id
    private String title;//内容标题
    private String secondTitle;//副标题 没有时则和主标题一样
    private String publishTime;//发布时间
    private List<PElement> content;//正文链：正文链里的id也是newFormat的id
    private String source;//来源
    // private String tagType;//标签类型 粗略标签 例如：军事、生活
    // private String tag;//军事装备
    private int contentType;//获取的是内容、链接、内容+链接1\2\3
    // private Set<AHref> needCollectUrl;//需要采集的url
    private String url;//当前链接
}
```

##### PElement

```java
package com.datacollection.unit.model.parser;

import java.io.Serializable;

import org.jsoup.nodes.Element;

import lombok.Data;

@Data
public class PElement implements Serializable {
    private long id;//当前id
    private long sourceId;//信源id
    private static final long serialVersionUID = 89L;
    transient private Element element;
}

```

##### AHref

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

@Data
@EqualsAndHashCode(callSuper=false)
public class AHref extends PElement{
    private String url;
    private String title;
    private String className="AHref";
}

```



##### DivContent

```java
package com.datacollection.unit.model.parser;


import lombok.Data;
import lombok.EqualsAndHashCode;

@Data
@EqualsAndHashCode(callSuper=false)
public class DivContent extends PElement{
    private String tagName;
    private String content;
    private String className="DivContent";
}

```



##### DlTable

```java
package com.datacollection.unit.model.parser;

import java.util.LinkedHashMap;
import java.util.Map;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * dl表格：即html中使用dl标签的表格
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class DlTable extends PElement{
    //保证插入顺序
    private Map<String,String> dlTable = new LinkedHashMap<>();
    private String className="DlTable";
}

```



##### Figure

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

@Data
@EqualsAndHashCode(callSuper=false)
public class Figure extends PElement {
    private String title;
    private String description;
    private String url;//图片地址
    private String blockquote;
    private String type = "jpg";//图片类型 jpg jpeg png gif等
    private String className="Figure";
}

```



##### FileModel

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 文件类型的包括各种样式的pdf word excel txt等
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class FileModel extends PElement{
    private int type;//文件类型 doc\pdf\xls\xlsx\docx等其它格式other
    private String url="";
    private String className="FileModel";
}

```



##### HTitle

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 正文标题
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class HTitle extends PElement {
    //唯一标识id
    //标题内容
    private String title;
    //标题级别（主标题、副标题、段落标题） 最高标题是正 标题为0 
    private int level;
    private String className="HTitle";
}

```



##### HtmlTime

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

@Data
@EqualsAndHashCode(callSuper=false)
public class HtmlTime extends PElement{
    private String content;
    private String datetime;
    private String className="HtmlTime";
}

```



##### OlListTable

```java
package com.datacollection.unit.model.parser;

import java.util.ArrayList;
import java.util.List;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * ul类型和ol类型相同
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class OlListTable extends PElement{
    private List<String> listTable = new ArrayList<>();
    private String className="OlListTable";
}

```



##### PContent

```java
package com.datacollection.unit.model.parser;
import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 内容类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class PContent extends PElement{
    private String tagName;
    private String content;
    private String className="PContent";
}

```



##### Picture

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 图片类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class Picture extends PElement{
    private String title;
    private String description;
    //图片对应下载地址（本地已经下载的）
    private String url;
    private String type = "jpg";//图片类型 jpg jpeg png gif等
    private String className="Picture";
}

```



##### Publisher

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 发布者（可能是人也可能是机构或者组织）
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class Publisher extends PElement{
    private String publisher;
    private String className="Publisher";
}

```



##### PublishTime

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 发布日期类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class PublishTime extends PElement{
    //当前只获取数据不需要对日期进行解析
    private String date;
    private String className="PublishTime";
}

```



##### Table

```java
package com.datacollection.unit.model.parser;

import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 普通表格类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class Table extends PElement{
    private String title;
    //需要添加有序map按照对应的插入顺序可顺序取出(第一个键即是对应的表格头) 如果不存在表格头的则对应的键为字符串"null0"开始
    private Map<String,List<String>> content = new LinkedHashMap<>();
    private String className="Table";
}

```



##### Title

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 标题类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class Title extends PElement{
    //标题内容
    private String title;
    //标题级别（主标题、副标题、段落标题） 最高标题是正 标题为0 
    private int level;
    private String className="Title";
}

```



##### UlListTable

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

import java.util.ArrayList;
import java.util.List;

/**
 * ul类型和ol类型相同
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class UlListTable extends PElement{
    private List<String> listTable = new ArrayList<>();
    private String className="UlListTable";
}

```



##### UpdateTime

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 更新时间类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class UpdateTime extends PElement {
     //当前只获取数据不需要对日期进行解析
     private String date;
     private String className="UpdateTime";
}

```



##### Video

```java
package com.datacollection.unit.model.parser;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 音视频类型
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class Video extends PElement {
    private String url;
    private String className="Video";
}

```



##### NewsFormatSelect

```java
package com.datacollection.unit.model.news;

import java.util.List;

import com.datacollection.unit.model.entity.BaseSelect;

import lombok.Data;
import lombok.EqualsAndHashCode;

/**
 * 获取新闻内容的select结构
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class NewsFormatSelect extends BaseSelect{
    private String title;//标题对应的select
    private List<String> titleExclude;//排除的样式或者内容
    private String publishTime;//发布时期对应的select
    private List<String> publishTimeExclude;//排除样式或者内容
    private List<String> content;//获取内容的select
    private List<String> contentExclude;//内容排除不需要获取的内容（select或者内容）
    private String source;//来源
    private List<String> sourceExclude;//来源
    private List<String> needCollectUrlCss;//需要获取url的样式链表
    private List<String> needExcludeCollectUrlCss;//需要排除获取url的样式链表
    private List<String> needDeleteContents;//需要删除的指定内容
}
```

##### 

#### 搜索类型

##### SearchContentList

```java
package com.datacollection.unit.model.baidusearch;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import com.datacollection.unit.message.result.BaseResultMessage;

import lombok.Data;
import lombok.EqualsAndHashCode;
/**
 * 返回搜索内容message
 */
@Data
@EqualsAndHashCode(callSuper=false)
public class SearchContentList extends BaseResultMessage {
    List<SearchContentFormat> searchContentFormatList = new ArrayList<>();
    Map<Integer,String> pageIndexsHrefList = new HashMap<>();
}

```

##### SearchContentFormat

```java
package com.datacollection.unit.model.baidusearch;

import java.io.Serializable;

import lombok.Data;

/**
 * 搜索列表的内容
 */
@Data
public class SearchContentFormat implements Serializable {
    private static final long serialVersionUID = 12349011668L;
    private long id;//对应当前搜索的唯一id
    private int curPageIndex;//当前页数
    private String title;//标题
    private String shortContent;//摘要内容
    private String name;//网站名称
    private String contentUrl;//对应url
    private String imgUrl;//图片url
    private String publishTime;//发布时间
}

```

#### 社交媒体类型

##### TwitterResult

```java
package com.datacollection.unit.model.socialmedia;
import java.util.HashMap;
import java.util.Map;

import com.datacollection.unit.message.result.BaseResultMessage;

import lombok.Data;
import lombok.EqualsAndHashCode;
@Data
@EqualsAndHashCode(callSuper=false)
public class TwitterResult extends BaseResultMessage {
    private Map<String,TwitterText> twitterTextList = new HashMap<>();
    private Map<String,TwitterUser> twitterUser = new HashMap<>();
}

```

### 心跳消息模型：CollectionInfoMessageAndHardware

```java
package com.datacollection.unit.message;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
@NoArgsConstructor
@AllArgsConstructor
@Builder
@Data
public class CollectionInfoMessageAndHardware implements Serializable {
    public int threadTotal=0;//当前线程池大小
    public int reqingCount=0;//正在运行的信源数量
    public List<Long> reqingList = new ArrayList<>();//正在运行的信源列表
    public int queueTotal=0;//当前队列的大小
    public int usedQueueCount=0; //当前队列拥有信源的数量
    public List<Long> usedQueueList = new ArrayList<>();//当前队列拥有信源列表
    public  int cpuTotal = 0;
    public  double cpuUsage = 0;
    public  long memoryTotal = 0;
    public  long avaiLableMemorySize = 0;
    public  long upLink = 0;
    public  long downLink = 0;
    public  float upLinkSpeed = 0;
    public  float downLinkSpeed = 0;
    public  long startTime = 0;
    public  long diskSize = 0;//硬盘
    public  long freeDisk = 0;//剩余量
    public long pingTime;
    public long upLinkTotal = 0;
	public long downLinkTotal = 0;
}

```

## Proto Buffer

版本：3.19.4-win32

代码

```protobuf
syntax = "proto3"; //版本
import "google/protobuf/any.proto";
option java_package = "com.datacollection.unit.message";	
option java_outer_classname = "PageReqMessageBuffer";//生成的外部类名，同时也是文件名

message PageMessageBody
{
	enum DataType{
			CollectionInfoMessage =0;
			PageReqMessage = 1;
			ResultMessage = 2;
			ResultFile = 3;
			DynamicJarMsg = 4;
		}
	DataType data_type = 1;
	oneof dataBody{
        CollectionInfoMessage collectionInfoMessage = 2;
        PageReqMessage pageReqMessage = 3;
		ResultMessage resultMessage =  4;
		ResultFile resultFile = 5;
		DynamicJarMsg dynamicJarMsg = 6;
    }
}
message PageReqMessage {
    int64 id = 1;//当前请求id
    int64 preId = 2; //文件下载时保存的pagereq的id信息
	int64 flag = 3;
	int32 type = 4;
	int32 contentType = 5;
	string parserFullName = 6;
	bool used = 7;
	bool isTest = 8;
	string wsEndPoint = 9;
	string url = 10;
	map<string,string> reqParams = 11;
	map<string,string> reqCookies = 12;
	map<string,string> reqHeads = 13;
	string userAgent = 14;
	string referer = 15;
	int32 timeout = 16;
	bool isPost = 17;
	bool isExistPostFormBody = 18;
	map<string,string> postFormBody = 19;
	string text = 20;
	string requestMediaType = 21;
	bool validateHttps = 22;
	bool useProxy = 23;
	bool useProxyAuth = 24;
	string proxyIp = 25;
	int32 proxyPort = 26;
	string proxyUsername = 27;
	string proxyPassword = 28;
	repeated string filterUrl = 29;
	repeated string addUrl = 30;
	repeated string whiteUrlList = 31;
	repeated string waitUntil = 32;
	bool enableStatic = 33;
	google.protobuf.Any pipelineActionManage = 34;
	bool enableInterception = 35;
	google.protobuf.Any select = 36;
	int32 curPageIndex = 37;
	bool savePosition = 38;
	int32 priority = 39;
	bool trust = 40;
	int64 startTime = 41;
	int64 endTime = 42;
	int64 sourceId = 43;//信源id
	int32 subType = 44;
}
// 采集数据返回结果消息
message ResultMessage {
	int64 sourceId = 1; //对应信源的id
	bool status = 2; //是否获取成功
	string MD5 = 3;//内容对应的md5值
	google.protobuf.Any content = 4;//不同类型返回的数据不同
	//int64 fakeSnow = 5;//雪花id
	int32 contentType = 5;//判断内容是否为列表
	int64 id = 6;
	int64 preId = 7;
	string url = 8;
	repeated string links = 9; // 需要加入待采集的信源，如果是列表，则从这里取值
	map<string,string> files = 10; // 需要采集的文件列表 pagereq.text()
}
message ResultFile {
	int64 sourceId = 1; //对应信源的id
	int64 fakeSnow = 2; //采集单元生成的fakeSnow url preid
	int64 curId = 3; 
	int64 beginPos = 4;//开始位置
	int64 endPos = 5;//结束位置
	bytes content = 6;//传输内容
	int32 status = 7; //传输状态
	string url = 8;//返回结果文件的url
	int32 type = 9;//返回的类型:视频、图片、文档、其它
	string suffix = 10;//后缀名称
}
//采集单元信息 
message CollectionInfoMessage
{
	int32 threadTotal = 1;
	int32 reqingCount = 2;
	repeated int64 reqingList = 3;
	int32 queueTotal = 4;
	int32 usedQueueCount = 5;
	repeated int64 usedQueueList = 6;
	int32 cpuTotal = 7;
	double cpuUsage = 8;
	int64 memoryTotal = 9;
	int64 availableMemorySize = 10;
	int64 upLink = 11;
	int64 downLink = 12;
	float upLinkSpeed = 13;
	float downLinkSpeed = 14;
	int64 startTime = 15; //用于计算两次传输值计算带宽
	int64 diskSize = 16;
	int64 freeDisk = 17;
	int64 pingTime = 18;//发送消息时间 存储到调度池内则为ping的毫秒数
	int64 upLinkTotal = 19;
	int64 downLinkTotal = 20;
}

message DynamicJarMsg
{
	repeated string jarList = 1; // 采集单元需要更新的动态jar列表
	bytes jarContent = 2;//动态jar文件流列表
	string jarName = 3;//动态jar文件名称
	repeated string classList = 4; // 动态jar列表
	map<string,string> jars = 5; // 控制单元发送的动态jar信息
}
```

