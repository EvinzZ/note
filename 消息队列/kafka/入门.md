# Kafka入门

## 1.为什么使用消息队列

## 2.Kafka基本概念

- Broker：消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个kafka集群
- Topic：kafka根据topic对消息进行归类，发布到kafka集群的每条消息都需要指定一个topic
- producer：消息生产者，向broker发送消息的客户端
- consumer：消息消费者，从broker读取消息的客户端
- consumerGroup：每个consumer属于一个特定的consumer group，一条消息可以被多个不同的consumer group消费，但是一个consumer group中只能有一个consumer能够消费该消息
- partition：物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的

## 3.创建主题topic

执行命令创建名为"test"的topic，这个topic只有一个partition，并且备份因子也设置为1:

```bash
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```

查看当前kafka内有哪些topic

```bash
./kafka-topics.sh --list --zookeeper localhost:2181
```

## 4.发送消息

kafka自带了producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中，在默认情况下，每一个行会被当作一个独立的消息，使用kafka的发送消息的客户端，指定发送的kafka服务器地址和topic。

```bash
./kafka-console-producer.sh --broker-list 192.168.200.10:9092 --topic test
```

## 5.消费消息

对于consumer，kafka同样也写到了一个命令行客户端，会将获取到内容在命令行中进行输出，默认是消费最新的消息。使用kafka的消费者消息的客户端，从指定kafka服务器的指定topic中消费消息。

方式一：从最后一条消息的偏移量+1开始消费

```bash
./kafka-console-consumer.sh --bootstrap-server 192.168.200.10:9092 --topic test
```

方式二：从头开始消费

```bash
./kafka-console-consumer.sh --bootstrap-server 192.168.200.10:9092 --from beginning --topic test
```

注意：

- 消息会被存储
- 消息是顺序存储
- 消息是有偏移量的
- 消费时可以指明偏移量进行消费

生产者将消息发送给broker，broker会将消息保存着本地的日志文件中

```bash
/user/local/kafka/data/kafka-logs/主题-分区/000000.log
```

消息的保存是有序的，通过offset偏移量来描述消息的有序性

消费者消费消息时，也是通过offset来描述当前要消费的那条消息的位置

## 6.单播消息的实现

单播消息：一个消费组里只会有一个消费者能消费到某一个topic中的消息，于是可以创建多个消费者，这些消费者在同一个消费组中。

```bash
./kafka-console-consumer.sh --bootstrap-server 192.168.200.10:9092 --consumer-property group.id=testGroup --topic test
```

## 7.多播消息的实现

在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。

kafka实现多播，只需要让不同的消费者处于不同的消费组即可。

```bash
./kafka-console-consumer.sh --bootstrap-server 192.168.200.10:9092 --consumer-property group.id=testGroup1 --topic test1

./kafka-console-consumer.sh --bootstrap-server 192.168.200.10:9092 --consumer-property group.ud=testGroup2 --topic test
```

## 8.查看消费组及信息

```bash
# 查看当前主题下有哪些消费组
./kafka-consumer-groups.sh --bootstrap-server 192.168.200.10:9092 --list

# 查看消费组中的具体信息：比如当前偏移量、最后一条消息的偏移量、堆积的消息数量
./kafka-consumer-groups.sh --bootstrap-server 192.168.200.10:9092 --describe --group testGroup
```

- Current-offset：当前消费组的已消费偏移量
- Log-end-offset：主题对应分区消息的结束偏移量（HW）
- Lag：当前消费组未消费的消息数

## 9.分区和主题

### 9.1.主题topic

主题-topic在kafka中是一个逻辑的概念，kafka通过topic将消息进行分类，不同的topic会被订阅该topic的消费者消费

但是有一个问题，如果说Z和个topic中的消息非常非常多，多到需要几个T来存，因为消息是会被保存到log日志文件中的，为了解决这个文件过大的问题，kafka提成了partition分区的概念

### 9.2.分区partition

通过partition将一个topic中的消息分区来存储，这样的好处有：

- 分区存储，可以解决统一存储文件过大的问题
- 提供了读写的吞吐量，读和写可以同时在多个分区中进行

#### 9.2.1.为一个主题创建多个分区

```bash
 kafka-topics.sh --create --zookeeper 192.168.200.10:2181/kafka --replication-factor 1 --partitions 2 --topic test1
```

#### 9.2.2.查看topic的分区信息

```bash
./kafka-topics.sh --describe --zookeeper localhost:2181 --topic test1
```

分区的作用：

- 可以分布式存储
- 可以并行写

注意：

实际上是存在data/kafka-logs/test-0和test-1中的000000000000.log文件中

小细节：

定期将自己消息分区的offset提交给kafka内部topic：__consumer_offsets，提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset 的值，kafka会定期清理topic里的消息，最后就保留最新的那条数据

因为__consumer_offsets可能会接收高并发的请求，kafka默认给其他分配50分区（可以通过offsets.topic.num.partitions设置），这样可以通过加机器的方式抗大并发。

通过一下公式可以算出consumer消费的offset要提交到__consumer_offsets的那个分区

公式：`hash(consumerGroupId)%__consumer_offsets主题的分区数`