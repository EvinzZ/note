## index

一个索引就是一个拥有几分相似特征的文档的集合。

在一个集群中，可以定义任意多的索引。

## type

5.x	支持多种type

6.x	只能有一种type

7.x	默认不再支持自定义索引类型（默认类型为：_doc）

## document

一个文档是一个可被索引的基础信息单元，也就是一条数据

## field

相当于是数据表的字段，对文档数据根据不同属性进行的分类标识。

## mapping

mapping是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、分析器、是否被索引等等。这些都是映射里面可以设置的，其他就是处理ES里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。

## shards分片

一个索引可以存储超出单个节点硬件限制的最大数据。比如，一个具有10亿文档数据的索引占据1TB的磁盘空间，而任一节点都可能没有这样大的磁盘空间。或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，每一份 就称之为分片，当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。

分片很重要，主要有两个方面的原因：

1. 允许你水平/扩展你的内容容量。
2. 允许你在分片之上进行分布式的、并行的操作，进而提高性能 / 吞吐量

至于一个分片怎样分布，他的文档怎样聚合和搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的，无需过分关心。

## 副本 replicas

在一个网络 / 云的环境里，失败随时都可能发生，在某个分片 / 节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，ES允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片（副本）。

复制分片之所以重要，有两个重要原因：

- 在分片 / 节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不  原 / 主要 分片置于同一节点上是非常重要的。
- 扩展你的搜索量 / 吞吐量，因为搜索可以在所有的副本上并行运行。

## 分配 Allocation

将分片分配到某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。这个过程是由master节点完成的。



## 单节点集群

集群健康值 >> yellow：表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态





## 故障转移

	当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的cluster.name配置，他就会自动发现集群并加入到其中。但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。

## 水平扩容

	怎样为正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点：为了分散负载而对分片进行重新分配。（此时为1主分片1副本，数据节点则为6个）

#### 但是如果我们想要扩容超过6个节点怎么办？

	主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够存储的最大数据量。（实际大小取决于你的 数据、硬件和使用场景），但是，读操作——搜索和返回数据——可以同时被主分片或副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。
	
	在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。

## 数据写流程

1. 客户端请求集群节点（任意）- 协调节点
2. 协调节点将请求转换到指定的节点
3. 主分片需要将数据保存
4. 主分片需要将数据发送到副本
5. 副本保存后，进行反馈
6. 主分片进行反馈
7. 客户端获取反馈

## 数据读流程

1. 客户端发送查询请求到协调节点
2. 协调节点计算数据所在的分片以及全部的副本位置
3. 为了能够负载均衡，可以轮询所有节点
4. 将请求转发给具体的节点
5. 节点返回查询结果，将结果反馈给客户端



## 分片原理

分片是Elasticsearch最小的工作单元。

传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值需求的数据结构是倒排索引。

## 倒排索引

倒排索引也叫反向索引，通俗来讲正向索引是通过key找value，反向索引则是通过value找key。

## 文档搜索

早起的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。

倒排索引被写入磁盘后是不可改变的：它永远不会修改。

不变性有重要的价值：

- 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。
- 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。
- 其他缓存（像filter缓存），在索引的生命周期内始终有效。他们不需要在每次数据改变时被重建。因为数据不会变化。
- 写入单个大的倒排索引允许数据被压缩，减少磁盘I/O和需要被缓存到内存的索引的使用量。

## 动态更新索引

用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到，从最早的开始查询完后再对结果进行合并。

## 近实时搜索

随着按段搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。

磁盘在这里成为了瓶颈。提交一个新的段到磁盘需要一个fsync来确保段被物理地写入磁盘，这样在断电的时候就不会丢失数据，但是fsync操作代价很大；如果每次索引一个文档都去执行一次的话会造成很大的性能问题。

我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着fsync要从整个过程中被移除。

在ES和磁盘之间是文件系统缓存。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存，这一步代价会比较低，稍后再被刷新到磁盘，这一步代价比较高。不过只要文件已经在缓存中，就可以像其他文件一样被打开和读取了。

## 文档分析

分析包含下面的过程：

- 将一块文本分成适合于倒排索引的独立的词条

- 将这些词条统一化为标准格式以提高他们的“可搜索性”，或者recall分析器执行上面的工作。

  分析器是上是将三个功能封装到了一个包里：

  - 字符过滤器：首先，字符串按顺序通过每个字符过滤器。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将&转化成and。
  - 分词器：其次，字符串被分词器分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会被文本拆分成词条。
  - Token过滤器：最后，词条按顺序通过每个token过滤器。这个过程可能会改变词条（例如，小写化Quick），删除词条（例如，像a，and，the等无用词），或者增加词条（例如：像jump和leap这种同义词）。